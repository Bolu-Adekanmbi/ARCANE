> A really good text guesser

> Autocomplete on steroids!

> A text completion machine

Looks at some text and then predicts what text comes next.

Language models encode statistical information about a language and uses this information to predict next word likeliness based on provided context.

The basic unit of a language model is a [[Tokenization#Token?|token]]

Language models can be trained using [[Self-supervised Learning|self-supervision]] while many other models require supervision. <â€” This contributed to the BOOM in scale for [[Large Language Models|LLMs]]

### Types
- [[Masked Language Model]]
- [[Autoregressive Language Model]]

Language models are probabilistic.

#### Completion tasks
Language Models are powerful because a wide range of tasks can be framed as completions tasks: Coding, translation, math problems, summarization are all completion tasks.

Spam classification of text can also be framed as a completion task.