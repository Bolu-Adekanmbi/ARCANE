> A process of creating smaller, faster models that still perform well

> Compressing a large model, while retaining as much performance as possible!

> Teaching a smaller model to copy the behavior of a larger model

> A large "teacher" model generates outputs, then a smaller "student" model learns to imitate those answers

You lose some detail but you keep most of what matters

A small decrease in quality for a significant increase in efficiency

Instead of learning from the raw data sources, the "student" model learns from the "teacher's" outputs